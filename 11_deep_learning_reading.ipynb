{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11장 - 심층 신경망 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 그래디언트 소실과 폭주 문제\n",
    "#### 11.1.1 세이비어 초기화와 He 초기화\n",
    "#### 11.1.2 수렴하지 않는 활성화 함수\n",
    "#### 11.1.3 배치 정규화\n",
    "#### 11.1.4 그래디언트 클리핑\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 미리 훈련된층 재사용하기\n",
    "#### 11.2.1 텐서플로 모델 재사용하기\n",
    "#### 11.2.2 다른 프레임워크의 모델 재사용하기\n",
    "#### 11.2.3 신경망의 하위층 학습에서 제외하기\n",
    "#### 11.2.4 동결된 층 캐싱하기\n",
    "#### 11.2.5 상위층을 변경, 삭제, 대체하기\n",
    "#### 11.2.6 모델 저장소\n",
    "#### 11.2.7 비지도 사전훈련\n",
    "#### 11.2.8 보조 작업으로 사전훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 고속 옵티마이저\n",
    "#### 11.3.1 모멘텀 최적화\n",
    "#### 11.3.2 네스테로프 가속 경사\n",
    "#### 11.3.3 AdaGrad\n",
    "#### 11.3.4 RMSProp\n",
    "#### 11.3.5 Adam 최적화\n",
    "#### 11.3.6 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 과대적합을 피하기 위한 규제 방법\n",
    "#### 11.4.1 조기종료\n",
    "#### 11.4.2 l1과 l2 규제\n",
    "#### 11.4.3 드롭아웃\n",
    "#### 11.4.4 맥스-노름 규제\n",
    "#### 11.4.5 데이터 증식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 실용적 가이드라인\n",
    "## 11.6 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext watermark\n",
    "# %watermark -v -p numpy,sklearn,scipy,matplotlib,tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 2와 파이썬 3 지원\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# 공통\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그림을 저장할 폴더\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 그래디언트 소실과 폭주 문제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래디언트 소실 : 출력층에서 입력층으로 역전파 알고리즘이 진행됨에 따라 그래디언트가 점점 작아져서 하위층(입력층)에 가까운 층들은 연결가중치가 거의 갱신되지 않는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_vanishing_gradient.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래디언트 폭주 : 반대로 그래디언트가 점점 커져서 여러개의 층이 비정상적으로 큰 가중치로 갱신(발산)되는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2010년 Xavier Glorot과 Yoshua Bengio의  \"Understandimg the Difficulty of Training Deep Feedforward Neural Networks\" 논문\n",
    "    - 로지스틱 시그모이드 활성화 함수 + 정규분포 가중치 초기화 사용 -> 각 층의 출력에서의 분산이 입력의 분산보다 더 커짐\n",
    "    - 신경망의 위쪽(출력층)으로 갈수록 층을 지날때마다 분산이 계속 커져 높은층(출력층)에서는 활성화 함수가 0 또는 1로 수렴하게 됨\n",
    "    - 시그모이드의 도함수는 f(1-f)이므로 함수의 값이 0 또는 1에 가까우면 도함수의 결과가 매우작아지고 층이 거듭될 수록 더 작아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('수렴', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('수렴', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('선형', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"로지스틱 활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.1 세이비어 초기화와 He 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래디언트 소실/발산을 완화하려면\n",
    "    - 적절한 신호가 흐르기 위해서는 각 층의 출력에 대한 분산이 입력에 대한 분산과 같아야 한다\n",
    "    - 역방향에서 층을 통과하기 전과 후의 그래디언트 분산이 동일해야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_bart.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Xavier Glorot과 Yoshua Bengio의 가중치 초기화 방법\n",
    "    - 출력의 분산은 입력 연결 수에 비례하여 늘어나므로 가중치의 분산을 1/n_inputs로 하여 입출력의 분산을 맞춘다\n",
    "    - 역방향일 경우에는 입출력이 반대로 바뀌어 분산이 1/n_outputs가 되어야 한다\n",
    "    - 두 방향에 대해 절충안으로 2/(n_inputs + n_outputs)를 가중치의 분산으로 한다\n",
    "    - tf.contrib.layers에 구현됨\n",
    "    - (세이비어 초기화 전략을 사용하면 훈련 속도를 상당히 높일 수 있다!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_xavier_init.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf의 xavier_initializer 모듈을 이용한 예시\n",
    "W = tf.get_variable(\"W\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* He 초기화\n",
    "    - ReLU 활성화 함수 및 ELU 등의 변종들을 위한 초기화 전략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.layers.dense는 기본적으로 세이비어 초기화함수를 사용하므로 아래와 같이 variance_scaling_initializer를 지정하여 He 초기화를 사용할 수 있다\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2 수렴하지 않는 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시그모이드 활성화 함수에 대한 오해\n",
    "    - 생물학적 뉴런과 비슷하므로 최선의 선택일 것이라는 오해\n",
    "    - 실제로는 ReLU가 더 잘 작동함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 죽은 ReLU (dying ReLU) 문제\n",
    "    - 훈련하는 동안 일부 뉴런이 0 이외의 값을 출력하지 않음\n",
    "    - 훈련 도중 가중치의 합이 음수가 되면 그 다음부턴 계속 0만 출력하게 됨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Leaky ReLU\n",
    "    - 하이퍼파라미터 alpha는 함수가 새는(leaky) 정도를 의미\n",
    "    - 새는 정도는 x < 0 일 때의 기울기이며 일반적으로 0.01로 설정함\n",
    "    - 작은 기울기가 leakyrelu를 절대 죽지 않게 만든다\n",
    "    - 아래 기술할 다른 ReLU 변현들에 비해 속도가 빠르다\n",
    "    - tf.nn.leaky_relu, tf.keras.layers.LeakyReLU 로 구현됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_leaky_relu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('통과', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU 활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RReLU (randomized leaky ReLU)\n",
    "    - 훈련 동안 주어진 범위 내에서 alpha를 무작위로 선택하고, 테스트 시에는 평균을 사용하는 방법\n",
    "    - 신경망이 과대적합시 사용하기 좋음\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PReLU(parametric leaky ReLU)\n",
    "    - alpha가 훈련 동안 학습되는 ReLU\n",
    "    - alpha가 하이퍼파라미터가 아니라 역전파에 의해 갱신되므로, 훈련세트가 클 경우에 사용하기 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ELU (exponential linear unit)\n",
    "    - 다른 모든 ReLU의 성능을 앞지르는 활성화 함수\n",
    "    - alpha값은 x가 음수일 때 수렴할 값을 설정\n",
    "    - x < 0일 떄, 음숫값이 들어오므로 평균 출력이 0에 더 가까워짐 -> 그래디언트 소실 완화\n",
    "    - x < 0이어도 그래디언트가 0이 아니므로 죽은 ReLU 문제가 생기지 않음\n",
    "    - alpha가 1이면 x = 0에서 연속적이므로 모든면에서 매끄러워서 경사하강법의 속도를 높여줌\n",
    "    - 단, ReLU나 ReLU의 변종 함수들에 비해 계산이 느리다\n",
    "    - tf.nn.elu, tf.keras.layers.ELU로 구현됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_ELU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_exp_func.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU 활성화 함수 ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로에서 ELU를 구현하는 것은 간단합니다. 층을 구성할 때 활성화 함수에 지정하기만 하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 활성화 함수는 Günter Klambauer, Thomas Unterthiner, Andreas Mayr가 2017년에 쓴 [논문](https://arxiv.org/pdf/1706.02515.pdf)에서 소개되었습니다(나중에 책에 추가하겠습니다). 훈련할 때 SELU 활성화 함수를 사용한 완전 연결 신경망은 스스로 정규화를 합니다. 각 층의 출력은 훈련하는 동안 같은 평균과 분산을 유지하려는 경향이 있어 그래디언트 소실과 폭주 문제를 해결합니다. 이 활성화 함수는 심층 신경망에서 다른 활성화 함수보다 뛰어난 성능을 내므로 꼭 이 함수를 시도해봐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU 활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 SELU 하이퍼파라미터(`scale`과 `alpha`)는 평균이 0, 표준 편차가 1에 가깝게 유지되도록 조정합니다(입력도 평균이 0, 표준 편차가 1로 표준화되었다고 가정합니다). 이 활성화 함수를 사용하면 100층으로 된 심층 신경망도 그래디언트 소실/폭주 문제없이 모든 층에서 대략 평균이 0이고 표준 편차가 1을 유지합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "층 0: -0.26 < 평균 < 0.27, 0.74 < 표준 편차 < 1.27\n",
      "층 10: -0.24 < 평균 < 0.27, 0.74 < 표준 편차 < 1.27\n",
      "층 20: -0.17 < 평균 < 0.18, 0.74 < 표준 편차 < 1.24\n",
      "층 30: -0.27 < 평균 < 0.24, 0.78 < 표준 편차 < 1.20\n",
      "층 40: -0.38 < 평균 < 0.39, 0.74 < 표준 편차 < 1.25\n",
      "층 50: -0.27 < 평균 < 0.31, 0.73 < 표준 편차 < 1.27\n",
      "층 60: -0.26 < 평균 < 0.43, 0.74 < 표준 편차 < 1.35\n",
      "층 70: -0.19 < 평균 < 0.21, 0.75 < 표준 편차 < 1.21\n",
      "층 80: -0.18 < 평균 < 0.16, 0.72 < 표준 편차 < 1.19\n",
      "층 90: -0.19 < 평균 < 0.16, 0.75 < 표준 편차 < 1.20\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100))\n",
    "for layer in range(100):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1/100))\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=1)\n",
    "    stds = np.std(Z, axis=1)\n",
    "    if layer % 10 == 0:\n",
    "        print(\"층 {}: {:.2f} < 평균 < {:.2f}, {:.2f} < 표준 편차 < {:.2f}\".format(\n",
    "            layer, means.min(), means.max(), stds.min(), stds.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로 1.4 버전에 `tf.nn.selu()` 함수가 추가되었습니다. 이전 버전을 사용할 때는 다음 구현을 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 SELU 활성화 함수는 일반적인 드롭아웃과 함께 사용할 수 없습니다(드롭아웃은 SELU 활성화 함수의 자동 정규화 기능을 없애버립니다). 다행히 같은 논문에 실린 알파 드롭아웃(Alpha Dropout)을 사용할 수 있습니다. 텐서플로 1.4에 `tf.contrib.nn.alpha_dropout()`이 추가되었습니다(Linz 대학교 생물정보학 연구소(Institute of Bioinformatics)의 Johannes Kepler가 만든 [구현](https://github.com/bioinf-jku/SNNs/blob/master/selu.py)을 확인해 보세요)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELU 활성화 함수를 사용한 신경망을 만들어 MNIST 문제를 풀어 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련할 차례입니다. 입력을 평균 0, 표준 편차 1로 스케일 조정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.88 검증 세트 정확도: 0.923\n",
      "5 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9574\n",
      "10 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9664\n",
      "15 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9684\n",
      "20 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9694\n",
      "25 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9688\n",
      "30 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9694\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.97\n"
     ]
    }
   ],
   "source": [
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.3 배치 정규화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ELU 등 ReLU 응용 함수와 He 초기화를 사용하면 훈련 초기단계에서 그래디언트 소실/폭주를 크게 감소시킬 수 있지만, 훈련 중 다시 발생할 수 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 내부 공변량 변화 문제\n",
    "    - 훈련하는 동안 이전 층의 파라미터가 변함에 따라 각 층에 들어오는 입력의 분포가 변하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2015년 Sergey Ioffe, Christian Szegedy가 배치 정규화 (Batch Normalization, BN) 기법을 제안함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 정규화\n",
    "    - 각 층에서 데이터의 분포를 정규화하는 기법\n",
    "    - 입력 데이터의 평균이 0이 되도록 정규화 및 스케일링하고 이동시킴\n",
    "    - 테스트 시에는 전체 훈련 세트의 평균과 표준편차를 대신 사용함\n",
    "    - 배치 정규화가 적용된 모든 층은 gamma(스케일), beta(이동), mu(평균), sigma(표준편차) 총 4개의 파라미터를 학습하게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_bn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 정규화의 성능\n",
    "    - 로지스틱 등 수렴되는 활성화 함수를 사용해도 소실 문제가 크게 감소됨\n",
    "    - 네트워크가 가중치 초기화에 덜 민감해짐\n",
    "    - 학습률을 크게 줄 수 있어 학습 속도가 개선됨\n",
    "    - 배치 정규화가 규제 역할을 하므로 다른 규제 기법의 필요성이 줄어듦\n",
    "    - \"사람의 판단 능력을 뛰어 넘는 4.9%의 top-5 검증 에러를 달성함\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 정규화의 단점\n",
    "    - 모델의 복잡도 증가\n",
    "    - 실행 시간이 오래 걸림. 층마다 추가되는 계산으로 인해 신경망의 예측이 느려짐 -> 예측이 빨라야 하는 경우에 사용하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텐서플로우 모듈\n",
    "    - tf.nn.batch_normalization : 평균, 표준편차를 직접 계산해 입력해야하며, 스케일 조정과 이동을 위한 파라미터를 생성해야 함\n",
    "    - tf.layers.batch_normalization : 모든 일을 대신 해주는 layer\n",
    "    - tf.keras.layers.BatchNormalization : tf.keras 버전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 은닉층의 활성화 함수 전에 배치 정규화를 추가하기 위해 ELU 활성화 함수를 배치 정규화 층 이후에 수동으로 적용하겠습니다.\n",
    "\n",
    "노트: `tf.layers.dense()` 함수가 (책에서 사용하는) `tf.contrib.layers.arg_scope()`와 호환되지 않기 때문에 대신 파이썬의 `functools.partial()` 함수를 사용합니다. 이를 사용해 `tf.layers.dense()`에 필요한 매개변수가 자동으로 설정되도록 `my_dense_layer()`를 만듭니다(그렇지 않으면 `my_dense_layer()`를 호출할 때마다 덮어씌여질 것입니다). 다른 코드는 이전과 비슷합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)  # momentum 값은 이동평균 계산에 사용됨\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 매개변수를 계속 반복해서 쓰지 않도록 파이썬의 `partial()` 함수를 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 층에 ELU 활성화 함수와 배치 정규화를 사용하여 MNIST를 위한 신경망을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노트: 배치 정규화를 위해 별도의 업데이트 연산을 실행해 주어야 합니다(`sess.run([training_op, extra_update_ops],...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.8952\n",
      "1 검증 세트 정확도: 0.9202\n",
      "2 검증 세트 정확도: 0.9318\n",
      "3 검증 세트 정확도: 0.9422\n",
      "4 검증 세트 정확도: 0.9468\n",
      "5 검증 세트 정확도: 0.954\n",
      "6 검증 세트 정확도: 0.9568\n",
      "7 검증 세트 정확도: 0.96\n",
      "8 검증 세트 정확도: 0.962\n",
      "9 검증 세트 정확도: 0.9638\n",
      "10 검증 세트 정확도: 0.9662\n",
      "11 검증 세트 정확도: 0.9682\n",
      "12 검증 세트 정확도: 0.9672\n",
      "13 검증 세트 정확도: 0.9696\n",
      "14 검증 세트 정확도: 0.9706\n",
      "15 검증 세트 정확도: 0.9704\n",
      "16 검증 세트 정확도: 0.9718\n",
      "17 검증 세트 정확도: 0.9726\n",
      "18 검증 세트 정확도: 0.9738\n",
      "19 검증 세트 정확도: 0.9742\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어!? MNIST 정확도가 좋지 않네요. 물론 훈련을 더 오래하면 정확도가 높아지겠지만 이런 얕은 신경망에서는 배치 정규화와 ELU가 큰 효과를 내지 못합니다. 대부분 심층 신경망에서 빛을 발합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "업데이트 연산에 의존하는 훈련 연산을 만들 수도 있습니다:\n",
    "\n",
    "```python\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)\n",
    "```\n",
    "\n",
    "이렇게 하면 훈련할 때 `training_op`만 평가하면 텐서플로가 업데이트 연산도 자동으로 실행할 것입니다:\n",
    "\n",
    "```python\n",
    "sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한가지 더, 훈련될 변수 개수가 전체 전역 변수 개수보다 적습니다. 이동 평균을 위한 변수는 훈련되는 변수가 아니기 때문입니다. 미리 학습한 신경망을 재사용할 경우(아래 참조) 이런 훈련되지 않는 변수를 놓쳐서는 안됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.4 그래디언트 클리핑\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래디언트 클리핑 (Gradient Clipping)\n",
    "    - 역전파도리 때 일정 임계값을 넘어서지 못하게 그래디언트를 단순히 잘라내는 방법\n",
    "    - 순환신경망(14장)에서 널리 사용되며 보통은 BN이 우선시된다\n",
    "    - Optimizer의 minimize() 함수는 그래디언트 계산과 적용을 모두 수행하므로 compute_gradients(), clip_by_value(), apply_gradients() 세 개 함수로 분할하여 적용해야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST를 위한 간단한 신경망을 만들고 그래디언트 클리핑을 적용해 보겠습니다. 시작 부분은 이전과 동일합니다(학습한 모델을 재사용하는 예를 만들기 위해 몇 개의 층을 더 추가했습니다. 아래 참조):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 그래디언트 클리핑을 적용합니다. 먼저 그래디언트를 구한 다음 `clip_by_value()` 함수를 사용해 클리핑하고 적용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)  # 그래디언트를 -1.0 ~ 1.0 사이로 클리핑해서 적용한다 \n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 300) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_and_vars[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'hidden1/kernel:0' shape=(784, 300) dtype=float32_ref>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_and_vars[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.288\n",
      "1 검증 세트 정확도: 0.7936\n",
      "2 검증 세트 정확도: 0.8798\n",
      "3 검증 세트 정확도: 0.906\n",
      "4 검증 세트 정확도: 0.9164\n",
      "5 검증 세트 정확도: 0.9218\n",
      "6 검증 세트 정확도: 0.9296\n",
      "7 검증 세트 정확도: 0.9358\n",
      "8 검증 세트 정확도: 0.9382\n",
      "9 검증 세트 정확도: 0.9414\n",
      "10 검증 세트 정확도: 0.9456\n",
      "11 검증 세트 정확도: 0.9474\n",
      "12 검증 세트 정확도: 0.9478\n",
      "13 검증 세트 정확도: 0.9534\n",
      "14 검증 세트 정확도: 0.9568\n",
      "15 검증 세트 정확도: 0.9566\n",
      "16 검증 세트 정확도: 0.9574\n",
      "17 검증 세트 정확도: 0.959\n",
      "18 검증 세트 정확도: 0.9622\n",
      "19 검증 세트 정확도: 0.9612\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 미리 훈련된 층 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전이 학습 (transfer learning)\n",
    "    - 큰 규모의 DNN을 처음부터 새로 훈련시키는 것은 좋지 못함\n",
    "    - 비슷한 유형의 문제를 처리한 신경망을 찾아 하위층을 재사용하는 것이 훈련속도도 빠르고 필요한 학습 데이터도 적음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ooo](img_11_transfer_learning.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.1 텐서플로 모델 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 저장된 모델 로드하여 새로운 데이터셋으로 학습하기\n",
    "\n",
    "먼저 그래프 구조를 로드해야 합니다. `import_meta_graph()` 함수가 그래프 연산들을 로드하여 기본 그래프에 적재하고 모델의 상태를 복원할 수 있도록 `Saver` 객체를 반환합니다. 기본적으로 `Saver` 객체는 `.meta` 확장자를 가진 파일에 그래프 구조를 저장하므로 이 파일을 로드해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 훈련해야 할 모든 연산을 가져와야 합니다. 그래프 구조를 모를 때는 모든 연산을 출력해 볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "웁스, 연산이 엄청 많네요! 텐서보드로 그래프를 시각화해보는 것이 더 좋을 것 같습니다. 다음 코드는 주피터에서 그래프를 그려줍니다(만약 브라우저에서 보이지 않는다면 `FileWriter`로 그래프를 저장한 다음 텐서보드에서 열어 보세요):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 연산을 찾았다면 그래프의 `get_operation_by_name()`이나 `get_tensor_by_name()` 메서드를 사용하여 추출할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 모델을 만들 때 다른 사람이 재사용하기 쉽게 연산에 명확한 이름을 부여하고 문서화를 하는 것이 좋습니다. 또 다른 방법은 처리해야 할 중요한 연산들을 모두 모아 놓은 컬렉션을 만드는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하면 모델을 재사용할 때 다음과 같이 간단하게 쓸 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 세션을 시작하고 모델을 복원하여 준비된 훈련 데이터로 훈련을 계속할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    # 모델 훈련 계속하기..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 테스트를 해보죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9636\n",
      "1 검증 세트 정확도: 0.9632\n",
      "2 검증 세트 정확도: 0.9658\n",
      "3 검증 세트 정확도: 0.9652\n",
      "4 검증 세트 정확도: 0.9646\n",
      "5 검증 세트 정확도: 0.965\n",
      "6 검증 세트 정확도: 0.969\n",
      "7 검증 세트 정확도: 0.9682\n",
      "8 검증 세트 정확도: 0.9682\n",
      "9 검증 세트 정확도: 0.9684\n",
      "10 검증 세트 정확도: 0.9704\n",
      "11 검증 세트 정확도: 0.971\n",
      "12 검증 세트 정확도: 0.9668\n",
      "13 검증 세트 정확도: 0.97\n",
      "14 검증 세트 정확도: 0.9712\n",
      "15 검증 세트 정확도: 0.9726\n",
      "16 검증 세트 정확도: 0.9718\n",
      "17 검증 세트 정확도: 0.971\n",
      "18 검증 세트 정확도: 0.9712\n",
      "19 검증 세트 정확도: 0.9712\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import_meta_graph() 없이 직접 코드로 그래프 구현\n",
    "\n",
    "또 다른 방법으로 원본 그래프를 만든 파이썬 코드에 접근할 수 있다면 `import_meta_graph()` 대신 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 훈련을 계속할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9642\n",
      "1 검증 세트 정확도: 0.9632\n",
      "2 검증 세트 정확도: 0.9656\n",
      "3 검증 세트 정확도: 0.9652\n",
      "4 검증 세트 정확도: 0.9646\n",
      "5 검증 세트 정확도: 0.9652\n",
      "6 검증 세트 정확도: 0.9688\n",
      "7 검증 세트 정확도: 0.9686\n",
      "8 검증 세트 정확도: 0.9682\n",
      "9 검증 세트 정확도: 0.9686\n",
      "10 검증 세트 정확도: 0.9704\n",
      "11 검증 세트 정확도: 0.9712\n",
      "12 검증 세트 정확도: 0.967\n",
      "13 검증 세트 정확도: 0.9698\n",
      "14 검증 세트 정확도: 0.9708\n",
      "15 검증 세트 정확도: 0.9724\n",
      "16 검증 세트 정확도: 0.9718\n",
      "17 검증 세트 정확도: 0.9712\n",
      "18 검증 세트 정확도: 0.9708\n",
      "19 검증 세트 정확도: 0.9712\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import한 그래프에 새로운 layer 추가하기\n",
    "\n",
    "일반적으로 하위층만 재사용할 것입니다. `import_meta_graph()`를 사용하면 전체 그래프를 로드하지만 필요하지 않은 부분은 무시하면 됩니다. 이 예에서는 학습된 3번째 층 위에 4번째 은닉층을 새로 추가합니다(원래 4번째 층은 무시됩니다). 새로운 출력층도 추가하고 이 출력으로 손실을 계산하고 이를 최소화하기 위한 새로운 옵티마이저를 만듭니다. 전체 그래프(원본 그래프 전체와 새로운 연산)를 저장할 새로운 `Saver` 객체와 새로운 모든 변수를 초기화할 초기화 연산도 필요합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # 새 층\n",
    "n_outputs = 10  # 새 층\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9118\n",
      "1 검증 세트 정확도: 0.9378\n",
      "2 검증 세트 정확도: 0.9462\n",
      "3 검증 세트 정확도: 0.9502\n",
      "4 검증 세트 정확도: 0.9526\n",
      "5 검증 세트 정확도: 0.9524\n",
      "6 검증 세트 정확도: 0.9568\n",
      "7 검증 세트 정확도: 0.96\n",
      "8 검증 세트 정확도: 0.9612\n",
      "9 검증 세트 정확도: 0.961\n",
      "10 검증 세트 정확도: 0.9632\n",
      "11 검증 세트 정확도: 0.9628\n",
      "12 검증 세트 정확도: 0.965\n",
      "13 검증 세트 정확도: 0.9654\n",
      "14 검증 세트 정확도: 0.9666\n",
      "15 검증 세트 정확도: 0.967\n",
      "16 검증 세트 정확도: 0.9674\n",
      "17 검증 세트 정확도: 0.9682\n",
      "18 검증 세트 정확도: 0.9686\n",
      "19 검증 세트 정확도: 0.9676\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 모델을 만든 파이썬 코드에 접근할 수 있다면 필요한 부분만 재사용하고 나머지는 버릴 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # 재사용\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 이전에 학습된 모델을 복원하기 위해 (복원할 변수 리스트를 전달합니다. 그렇지 않으면 그래프와 맞지 않는다고 에러를 낼 것입니다) `Saver` 객체를 하나 만들고 훈련이 끝난 후 새로운 모델을 저장하기 위해 또 다른 `Saver` 객체를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9024\n",
      "1 검증 세트 정확도: 0.9332\n",
      "2 검증 세트 정확도: 0.943\n",
      "3 검증 세트 정확도: 0.947\n",
      "4 검증 세트 정확도: 0.9516\n",
      "5 검증 세트 정확도: 0.9532\n",
      "6 검증 세트 정확도: 0.9558\n",
      "7 검증 세트 정확도: 0.9592\n",
      "8 검증 세트 정확도: 0.9586\n",
      "9 검증 세트 정확도: 0.9608\n",
      "10 검증 세트 정확도: 0.9626\n",
      "11 검증 세트 정확도: 0.962\n",
      "12 검증 세트 정확도: 0.964\n",
      "13 검증 세트 정확도: 0.9662\n",
      "14 검증 세트 정확도: 0.966\n",
      "15 검증 세트 정확도: 0.9662\n",
      "16 검증 세트 정확도: 0.9672\n",
      "17 검증 세트 정확도: 0.9674\n",
      "18 검증 세트 정확도: 0.9682\n",
      "19 검증 세트 정확도: 0.9678\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                        # 책에는 없음\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # 책에는 없음\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})    # 책에는 없음\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.2 다른 프레임워크의 모델 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 예에서는 재사용하려는 각 변수에 대해 변수 초기화 할당 연산을 찾고, 초기화 될 값에 해당하는 두 번째 입력 핸들을 구합니다. 초기화가 실행될 때 여기에 `feed_dict` 매개변수를 사용하여 초깃값 대신 원하는 값을 주입합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # 다른 프레임워크로부터 가중치를 로드\n",
    "original_b = [7., 8., 9.]                 # 다른 프레임워크로부터 편향을 로드\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] 모델의 나머지 부분을 구성\n",
    "\n",
    "# hidden1 변수의 할당 노드에 대한 핸들을 구합니다\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] 새 작업에 모델을 훈련시킵니다\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방법은 전용 할당 노드와 플레이스홀더를 만든는 것입니다. 이 방법은 더 번거롭고 효율적이지 않지만 하려는 방식이 잘 드러나는 방법입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # 다른 프레임워크로부터 가중치를 로드\n",
    "original_b = [7., 8., 9.]                 # 다른 프레임워크로부터 편향을 로드\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] 모델의 나머지를 구성\n",
    "\n",
    "# hidden1 변수의 할당 노드에 대한 핸들을 구합니다\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):  # 루트 범위\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "\n",
    "# 전용 플레이스홀더와 할당 노드를 만듭니다\n",
    "original_weights = tf.placeholder(tf.float32, shape=(n_inputs, n_hidden1))\n",
    "original_biases = tf.placeholder(tf.float32, shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights, original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights, feed_dict={original_weights: original_w})\n",
    "    sess.run(assign_hidden1_biases, feed_dict={original_biases: original_b})\n",
    "    # [...] 새 작업에 모델을 훈련시킵니다\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_collection()`에 `scope`를 지정하여 변수의 핸들을 가져올 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 그래프의 `get_tensor_by_name()` 메서드를 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.3 하위층 동결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optimizer 변수목록에서 제외하기\n",
    "\n",
    "Optimizer의 minimize() 함수를 실행할 때, var_list 파라미터에 동결할 층들을 제외하고 전달하는 방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # 재사용\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):                                         # 책에는 없음\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     # 책에는 없음\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.8962\n",
      "1 검증 세트 정확도: 0.9288\n",
      "2 검증 세트 정확도: 0.9402\n",
      "3 검증 세트 정확도: 0.944\n",
      "4 검증 세트 정확도: 0.9482\n",
      "5 검증 세트 정확도: 0.9506\n",
      "6 검증 세트 정확도: 0.9508\n",
      "7 검증 세트 정확도: 0.9538\n",
      "8 검증 세트 정확도: 0.9552\n",
      "9 검증 세트 정확도: 0.9564\n",
      "10 검증 세트 정확도: 0.9562\n",
      "11 검증 세트 정확도: 0.9568\n",
      "12 검증 세트 정확도: 0.9572\n",
      "13 검증 세트 정확도: 0.9578\n",
      "14 검증 세트 정확도: 0.9592\n",
      "15 검증 세트 정확도: 0.9578\n",
      "16 검증 세트 정확도: 0.9576\n",
      "17 검증 세트 정확도: 0.9604\n",
      "18 검증 세트 정확도: 0.9592\n",
      "19 검증 세트 정확도: 0.9604\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.stop_gradient() 사용하기\n",
    "\n",
    "tf.stop_gradient()가 적용된 아래의 모든 층이 고정됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # 동결층 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # 동결층 재사용\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # 동결하지 않고 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # 새로 만듦!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련하는 코드는 이전과 완전히 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.902\n",
      "1 검증 세트 정확도: 0.931\n",
      "2 검증 세트 정확도: 0.9434\n",
      "3 검증 세트 정확도: 0.9476\n",
      "4 검증 세트 정확도: 0.9516\n",
      "5 검증 세트 정확도: 0.9524\n",
      "6 검증 세트 정확도: 0.9524\n",
      "7 검증 세트 정확도: 0.9558\n",
      "8 검증 세트 정확도: 0.9554\n",
      "9 검증 세트 정확도: 0.956\n",
      "10 검증 세트 정확도: 0.9566\n",
      "11 검증 세트 정확도: 0.9552\n",
      "12 검증 세트 정확도: 0.9574\n",
      "13 검증 세트 정확도: 0.9578\n",
      "14 검증 세트 정확도: 0.958\n",
      "15 검증 세트 정확도: 0.9572\n",
      "16 검증 세트 정확도: 0.9564\n",
      "17 검증 세트 정확도: 0.9578\n",
      "18 검증 세트 정확도: 0.9592\n",
      "19 검증 세트 정확도: 0.958\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.4 동결된 층 캐싱하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # 동결층 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # 동결층 재사용 & 캐싱\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # 동결하지 않고 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.902\n",
      "1 검증 세트 정확도: 0.931\n",
      "2 검증 세트 정확도: 0.9434\n",
      "3 검증 세트 정확도: 0.9476\n",
      "4 검증 세트 정확도: 0.9516\n",
      "5 검증 세트 정확도: 0.9524\n",
      "6 검증 세트 정확도: 0.9524\n",
      "7 검증 세트 정확도: 0.9558\n",
      "8 검증 세트 정확도: 0.9554\n",
      "9 검증 세트 정확도: 0.956\n",
      "10 검증 세트 정확도: 0.9566\n",
      "11 검증 세트 정확도: 0.9552\n",
      "12 검증 세트 정확도: 0.9574\n",
      "13 검증 세트 정확도: 0.9578\n",
      "14 검증 세트 정확도: 0.958\n",
      "15 검증 세트 정확도: 0.9572\n",
      "16 검증 세트 정확도: 0.9564\n",
      "17 검증 세트 정확도: 0.9578\n",
      "18 검증 세트 정확도: 0.9592\n",
      "19 검증 세트 정확도: 0.958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) # 책에는 없음\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, # 책에는 없음\n",
    "                                                y: y_valid})             # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고속 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모멘텀 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네스테로프 가속 경사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       # 책에는 없음\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9654\n",
      "1 검증 세트 정확도: 0.9716\n",
      "2 검증 세트 정확도: 0.9726\n",
      "3 검증 세트 정확도: 0.9798\n",
      "4 검증 세트 정확도: 0.9798\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규제로 과대적합 피하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$과 $\\ell_2$ 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\ell_1$ 규제를 직접 구현해 보죠. 먼저 평상시처럼 모델을 만듭니다(간단하게 하기 위해 은닉층을 하나만 두겠습니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음, 층의 가중치에 대한 핸들을 얻어 크로스 엔트로피 손실에 $\\ell_1$ 손실(즉, 가중치의 절댓값)을 더해 전체 손실을 계산합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001 # l1 규제 하이퍼파라미터\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.831\n",
      "1 검증 세트 정확도: 0.871\n",
      "2 검증 세트 정확도: 0.8838\n",
      "3 검증 세트 정확도: 0.8934\n",
      "4 검증 세트 정확도: 0.8966\n",
      "5 검증 세트 정확도: 0.8988\n",
      "6 검증 세트 정확도: 0.9016\n",
      "7 검증 세트 정확도: 0.9044\n",
      "8 검증 세트 정확도: 0.9058\n",
      "9 검증 세트 정확도: 0.906\n",
      "10 검증 세트 정확도: 0.9068\n",
      "11 검증 세트 정확도: 0.9054\n",
      "12 검증 세트 정확도: 0.907\n",
      "13 검증 세트 정확도: 0.9084\n",
      "14 검증 세트 정확도: 0.9088\n",
      "15 검증 세트 정확도: 0.9064\n",
      "16 검증 세트 정확도: 0.9066\n",
      "17 검증 세트 정확도: 0.9066\n",
      "18 검증 세트 정확도: 0.9066\n",
      "19 검증 세트 정확도: 0.9052\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 방법으로는 `tf.layers.dense()` 함수에 규제 함수를 전달할 수 있습니다. 이 함수는 규제 손실을 계산하기 위한 연산을 만들고 규제 손실 컬렉션에 이 연산을 추가합니다. 모델 선언부는 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음, 동일한 매개변수를 매번 반복하지 않으려고 파이썬의 `partial()` 함수를 사용합니다. `kernel_regularizer` 매개변수를 지정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 손실에 규제 손실을 추가합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):                                     # 책에는 없음\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  # 책에는 없음\n",
    "        labels=y, logits=logits)                                # 책에는 없음\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   # 책에는 없음\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 평상시와 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.8274\n",
      "1 검증 세트 정확도: 0.8766\n",
      "2 검증 세트 정확도: 0.8952\n",
      "3 검증 세트 정확도: 0.9016\n",
      "4 검증 세트 정확도: 0.908\n",
      "5 검증 세트 정확도: 0.9096\n",
      "6 검증 세트 정확도: 0.9124\n",
      "7 검증 세트 정확도: 0.9154\n",
      "8 검증 세트 정확도: 0.9178\n",
      "9 검증 세트 정확도: 0.919\n",
      "10 검증 세트 정확도: 0.92\n",
      "11 검증 세트 정확도: 0.9224\n",
      "12 검증 세트 정확도: 0.9212\n",
      "13 검증 세트 정확도: 0.9228\n",
      "14 검증 세트 정확도: 0.9222\n",
      "15 검증 세트 정확도: 0.9218\n",
      "16 검증 세트 정확도: 0.9218\n",
      "17 검증 세트 정확도: 0.9228\n",
      "18 검증 세트 정확도: 0.9216\n",
      "19 검증 세트 정확도: 0.9214\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9254\n",
      "1 검증 세트 정확도: 0.9452\n",
      "2 검증 세트 정확도: 0.9492\n",
      "3 검증 세트 정확도: 0.9566\n",
      "4 검증 세트 정확도: 0.9606\n",
      "5 검증 세트 정확도: 0.9594\n",
      "6 검증 세트 정확도: 0.9606\n",
      "7 검증 세트 정확도: 0.9672\n",
      "8 검증 세트 정확도: 0.969\n",
      "9 검증 세트 정확도: 0.97\n",
      "10 검증 세트 정확도: 0.9676\n",
      "11 검증 세트 정확도: 0.968\n",
      "12 검증 세트 정확도: 0.971\n",
      "13 검증 세트 정확도: 0.9704\n",
      "14 검증 세트 정확도: 0.972\n",
      "15 검증 세트 정확도: 0.9702\n",
      "16 검증 세트 정확도: 0.9728\n",
      "17 검증 세트 정확도: 0.971\n",
      "18 검증 세트 정확도: 0.9736\n",
      "19 검증 세트 정확도: 0.9742\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 맥스 노름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 은닉층을 가진 간단한 MNIST 신경망을 만들어 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 첫 번째 은닉층의 가중치에 대한 핸들을 얻고 `clip_by_norm()` 함수를 사용해 가중치를 클리핑하는 연산을 만듭니다. 그런 다음 클리핑된 가중치를 가중치 변수에 할당하는 연산을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 층에 대해서도 동일하게 할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기와 연산과 `Saver` 객체를 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 훈련시킵니다. 이전과 매우 동일한데 `training_op`을 실행한 후에 `clip_weights`와 `clip_weights2` 연산을 실행하는 것만 다릅니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9568\n",
      "1 검증 세트 정확도: 0.9696\n",
      "2 검증 세트 정확도: 0.972\n",
      "3 검증 세트 정확도: 0.977\n",
      "4 검증 세트 정확도: 0.977\n",
      "5 검증 세트 정확도: 0.977\n",
      "6 검증 세트 정확도: 0.981\n",
      "7 검증 세트 정확도: 0.9814\n",
      "8 검증 세트 정확도: 0.9812\n",
      "9 검증 세트 정확도: 0.9822\n",
      "10 검증 세트 정확도: 0.9814\n",
      "11 검증 세트 정확도: 0.985\n",
      "12 검증 세트 정확도: 0.9822\n",
      "13 검증 세트 정확도: 0.9842\n",
      "14 검증 세트 정확도: 0.984\n",
      "15 검증 세트 정확도: 0.9848\n",
      "16 검증 세트 정확도: 0.984\n",
      "17 검증 세트 정확도: 0.9838\n",
      "18 검증 세트 정확도: 0.9842\n",
      "19 검증 세트 정확도: 0.9844\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              # 책에는 없음\n",
    "    init.run()                                                          # 책에는 없음\n",
    "    for epoch in range(n_epochs):                                       # 책에는 없음\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):  # 책에는 없음\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        # 책에는 없음\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                     # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")               # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 구현은 이해하기 쉽고 잘 작동하지만 조금 번거롭습니다. 더 나은 방법은 `max_norm_regularizer()` 함수를 만드는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # 규제 손실을 위한 항이 없습니다\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런 다음 (필요한 임계값을 지정해서) 맥스 노름 규제 매개변수에 넘길 함수를 만들기 위해 이 함수를 호출합니다. 은닉층을 만들 때 이 규제 함수를 `kernel_regularizer` 매개변수를 통해 전달할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 연산이 실행된 후에 가중치 클리핑 연산을 실행하는 것을 제외하면 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9558\n",
      "1 검증 세트 정확도: 0.9704\n",
      "2 검증 세트 정확도: 0.9728\n",
      "3 검증 세트 정확도: 0.9758\n",
      "4 검증 세트 정확도: 0.9766\n",
      "5 검증 세트 정확도: 0.9786\n",
      "6 검증 세트 정확도: 0.9818\n",
      "7 검증 세트 정확도: 0.9808\n",
      "8 검증 세트 정확도: 0.9812\n",
      "9 검증 세트 정확도: 0.981\n",
      "10 검증 세트 정확도: 0.9816\n",
      "11 검증 세트 정확도: 0.9824\n",
      "12 검증 세트 정확도: 0.9804\n",
      "13 검증 세트 정확도: 0.9822\n",
      "14 검증 세트 정확도: 0.9822\n",
      "15 검증 세트 정확도: 0.982\n",
      "16 검증 세트 정확도: 0.9816\n",
      "17 검증 세트 정확도: 0.9824\n",
      "18 검증 세트 정확도: 0.9822\n",
      "19 검증 세트 정확도: 0.9826\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")                # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 해답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11장의 연습문제는 [11_deep_learning_exercise](11_deep_learning_exercises.ipynb) 노트북에 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
